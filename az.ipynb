{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1\n",
    "dixt= {'boys': [72,68,70,69,74], 'girls': [63,65,69,62,61]}\n",
    "arr_boys =dixt['boys'] \n",
    "arr_girls =dixt['girls']\n",
    "res =[]\n",
    "for i,j in zip(arr_boys, arr_girls):\n",
    "    temp ={}\n",
    "    temp['Boys'] =i\n",
    "    temp['Girls'] =j\n",
    "    res.append(temp)\n",
    "print(res)\n",
    "\n",
    "\n",
    "# question2\n",
    "#  A. COMPUTE MEAN , STANDARD DEVIATION , AND VARIANCE OF A TWO DIMENSIONAL RANDOM INTEGER ARRAY ALONG THE SECOND AXIS.\n",
    "\n",
    "import numpy as np\n",
    "arr = np.random.randint(0,100,10)\n",
    "arr = arr.reshape(2,5)\n",
    "print(\"arr is \",arr)\n",
    "print(\"mean along 2nd axis is \", arr.mean(axis=1))\n",
    "print(\"variance : \",arr.var(axis=1))\n",
    "print(\"standard varaince \", arr.std(axis=1))\n",
    "#  B. GET THE INDICES OF THE SORTED ELEMENTS OF A GIVEN ARRAY\n",
    "\n",
    "b = [56,48,22,41,78,91,24,46,8,33]\n",
    "arr = np.array(b)\n",
    "sorted_ind = np.argsort(arr)\n",
    "print(sorted_ind)\n",
    "\n",
    "#  C. CREATE A 2- DIMENSIONAL ARRAY OF SIZE M X N INTEGER ELEMENTS , ALSO PRINT THE SHAPE , TYPE , AND DATA TYPE OF THE ARRAY AND THAN RESHAPE IT INTO N X M ARRAY , N AND M ARE USER INPUTS GIVEN AT THE RUN TIME.\n",
    "\n",
    "no_row = int(input(\"enter the number of rows : \"))\n",
    "no_col = int(input(\"enter the number of cols : \"))\n",
    "arr = np.random.randint(0,100,no_row * no_col)\n",
    "arr = arr.reshape(no_row,no_col)\n",
    "\n",
    "print(\"array is: \",arr)\n",
    "print(\"shape is \", arr.shape)\n",
    "print(\"data type \",arr.dtype)\n",
    "print(\"type is \", type(arr))\n",
    "print(\"\")\n",
    "print(f\"after reshape to {no_row} x {no_col} :\" , arr.reshape(no_col,no_row))\n",
    "\n",
    "#  D. TEST WHETHER THE ELEMENTS OF A GIVEN ARRAY ARE ZERO , NON ZERO , AND NAN , RECOED THE INDICES OF THESE ELEMENTS IN THREE SEPERATE ARRAYS\n",
    "\n",
    "arr = [12.,34.,56.,78, np.nan,0, -np.nan ,90]\n",
    "arr = np.array(arr)\n",
    "\n",
    "temp = 0\n",
    "arr_nan =[]\n",
    "arr_zero = []\n",
    "arr_nzero = []\n",
    "\n",
    "for i in arr:\n",
    "    if np.isnan(i)==True:\n",
    "        arr_nan.append(temp)\n",
    "    elif(i==0):\n",
    "        arr_zero.append(temp)\n",
    "    else:\n",
    "        arr_nzero.append(temp)\n",
    "        \n",
    "    temp +=1 \n",
    "print(\"nan : \",arr_nan)   \n",
    "print(\"zero : \",arr_zero)\n",
    "print(\"not zero : \",arr_nzero)\n",
    "\n",
    "\n",
    "# question 3\n",
    "# a. Identify and count missing values in a dataframe.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "\n",
    "c = 5\n",
    "r = 50\n",
    "\n",
    "arr = np.random.randint(100,size=(r,c))\n",
    "temp_arr_1d =  arr.reshape(c*r)\n",
    "temp_random_indexes = np.random.randint(r*c-1, size=int(temp_arr_1d.size*0.1))\n",
    "df = pd.DataFrame(temp_arr_1d)\n",
    "for i in temp_random_indexes:\n",
    "    df.loc[i] = np.nan\n",
    "\n",
    "df = pd.DataFrame(df.to_numpy().reshape(r,c))\n",
    "column_del = []\n",
    "\n",
    "for i in range(c):\n",
    "    print(f\"column {i} has \",50-df.loc[:,i].count(),\"Nan\")\n",
    "    if(50 -df.loc[:,i].count()) >=5:\n",
    "        column_del.append(i)\n",
    "        \n",
    "# output\n",
    "\n",
    "#  b. Drop the column having more than 5 null values.\n",
    "print(\"columns to be removed \",column_del)\n",
    "\n",
    "col_deleted =0\n",
    "for i in column_del:\n",
    "    df = df.drop(df.columns[i-col_deleted],axis=1)\n",
    "    col_deleted +=1\n",
    "print(df)    \n",
    "# output\n",
    "# c. Identify the row label having maximum of the sum of all values in a row and drop that row\n",
    "\n",
    "max_index = 0\n",
    "max_value = 0\n",
    "\n",
    "for i in range(r):\n",
    "    if df.loc[i].sum() > max_value:\n",
    "        max_value = df.loc[i].sum()\n",
    "        max_index = i\n",
    "\n",
    "print(\"index to be removed \",max_index)\n",
    "df = df.drop(max_index)\n",
    "print(df)\n",
    "# output\n",
    "#  d. Sort the dataframe on the basis of the first column\n",
    "\n",
    "df = df.sort_values(by=df.columns[0])\n",
    "print(df)\n",
    "# output\n",
    "#  e. Remove all duplicates from the first column.\n",
    "\n",
    "df = df.drop_duplicates() \n",
    "\n",
    "print(df)\n",
    "# output\n",
    "\n",
    "# f. Find the correlation between first and second column and covariance between second and third column \n",
    "\n",
    "#first removing the nan values bcoz it don't works with cov , or corrcoef\n",
    "df = df.dropna()\n",
    "\n",
    "corr = np.corrcoef(df.iloc[:,0], df.iloc[:,1] )\n",
    "print(corr)\n",
    "\n",
    "covv = np.cov(df.iloc[:,0], df.iloc[:,1])\n",
    "\n",
    "print(\"covarience--->\",covv)\n",
    "# output\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3,3) , dpi=500)\n",
    "sns.heatmap(corr,annot=True,fmt=\".2f\",linewidth=.5)\n",
    "plt.show()\n",
    "# output\n",
    "#  g. Detect the outliers and remove the rows having outliers.\n",
    "\n",
    "data = df.iloc[:,0]\n",
    "data_arr  = data.to_numpy()\n",
    "\n",
    "q1 ,q2, q3  = np.percentile(sorted(data_arr) , [25,50,75])\n",
    "print(data_arr)\n",
    "print(\"total -->\",data_arr.size)\n",
    "print(\"q1 --> \",q1)\n",
    "print(\"q2 --> \",q2)\n",
    "print(\"q3 --> \",q3)\n",
    "\n",
    "iqr = q3 - q1\n",
    "\n",
    "print(\"iqr  --> \",iqr)\n",
    "\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "print(\"lower bound\",lower_bound)\n",
    "print(\"upper_bound\",upper_bound)\n",
    "outliers = [i for i in data_arr if i<= lower_bound or i >=upper_bound]\n",
    "print(outliers)\n",
    "# output\n",
    "#  h. Discretize second column and create 5 bins\n",
    "\n",
    "_arr = df.iloc[:,1]\n",
    "ss = pd.DataFrame(_arr.to_numpy())\n",
    "\n",
    "binn = pd.cut(ss.iloc[:,0],bins=5)\n",
    "print(binn)\n",
    "# output\n",
    "\n",
    "# question 4\n",
    "# . Consider two excel files having attendance of a workshop’s participants for two days. Each file has three\n",
    "# fields ‘Name’, ‘Time of joining’, duration (in minutes) where names are unique within a file. Note that duration\n",
    "# may take one of three values (30, 40, 50) only. Import the data into two dataframes and do the following:\n",
    "\n",
    "\n",
    "# a.) Perform merging of the two dataframes to find the names of students who had attended the workshop on both days.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "day1 = pd.read_excel('day1.xlsx')\n",
    "day2 = pd.read_excel('day2.xlsx')\n",
    "\n",
    "day1\n",
    "# output\n",
    "day2\n",
    "# output\n",
    "\n",
    "#students who attended on both days\n",
    "#inner bcoz we have to get common\n",
    "\n",
    "n_df = day1.merge(day2,on='Name',how='inner')\n",
    "print(n_df['Name'])\n",
    "# output\n",
    "# b.) Find names of all students who have attended workshop on either of the days\n",
    "\n",
    "#students who have attended workshop on either day\n",
    "\n",
    "# An outer join returns all \n",
    "#the rows from both DataFrames, filling in missing values with NaN where \n",
    "#there is no match.\n",
    "\n",
    "student_attended = day1.merge(day2,how='outer',on='Name')\n",
    "student_attended['Name']\n",
    "# output\n",
    "# c.) Merge two data frames row-wise and find the total number of records in the data frame.\n",
    "\n",
    " day1.merge(day2,how='outer')\n",
    "# output\n",
    "# d.)  Merge two data frames and use two columns names and duration as multi-row indexes. Generate descriptive statistics for this multi-index.\n",
    "\n",
    "day1.columns = ['Name','Time of joining','Duration']\n",
    "\n",
    "day1\n",
    "# output\n",
    "day2\n",
    "# output\n",
    "x =day1.merge(day2,how='outer')\n",
    "x\n",
    "# output\n",
    "x.set_index(['Name','Duration'])\n",
    "# output\n",
    "x = x.set_index(['Name','Duration'])\n",
    "# output\n",
    "x.describe()\n",
    "# output\n",
    "\n",
    "# question 5\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_iris()\n",
    "target = data['target']\n",
    "\n",
    "target.size\n",
    "# output\n",
    "target_names = data['target_names']\n",
    "target_names\n",
    "# output\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "df\n",
    "# output\n",
    "target =data['target']\n",
    "feature_names = data['feature_names']\n",
    "feature_names\n",
    "# output\n",
    "target\n",
    "# output\n",
    "\n",
    "feature_names\n",
    "# output\n",
    "#  a. Plot bar chart to show the frequency of each class label in the data\n",
    "\n",
    "df.columns = feature_names\n",
    "\n",
    "df['target'] = target\n",
    "\n",
    "df['class_label'] =df['target'].map({0:target_names[0],1:target_names[1],2:target_names[2]})\n",
    "df\n",
    "# output\n",
    "\n",
    "plt.hist(df['class_label'])\n",
    "plt.xlabel('classlabel')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('frequency of each label')\n",
    "# output\n",
    "#  b.) Draw a scatter plot for Petal width vs sepal width\n",
    "plt.scatter(df[\"petal width (cm)\"], df[\"sepal width (cm)\"])\n",
    "# output\n",
    "#  c. Plot density distribution for feature petal length.\n",
    "\n",
    "df['petal length (cm)'].plot(kind='density', color='skyblue')\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Distribution of Petal Length')\n",
    "plt.show()\n",
    "# output\n",
    "#  d. Use a pair plot to show pairwise bivariate distribution in the Iris Dataset\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# library is used to create a matrix of scatterplots for all pairs of numeric columns in a DataFrame.\n",
    "\n",
    "# It provides a quick visual overview of the relationships between variables in your dataset.\n",
    "\n",
    "sns.pairplot(df)\n",
    "# output\n",
    "\n",
    "# question 6\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('GameSales.csv',encoding='latin')\n",
    "df.head()\n",
    "# output\n",
    "#  a. Compute mean of a series grouped by another series\n",
    "df.groupby(['Genre'])['Global'].mean()\n",
    "# output\n",
    "#  b. Fill an intermittent time series to replace all missing dates with values of previous non-missing date.\n",
    "df.isnull().sum()  #to know which column contain null values\n",
    "# output\n",
    "df['Year'].fillna(method='ffill',inplace=True)\n",
    "df\n",
    "# output\n",
    "df.isnull().sum()  #check if above code have worked or not\n",
    "# output\n",
    "# c. Perform appropriate year-month string to dates conversion\n",
    "\n",
    "from datetime import datetime\n",
    "# output\n",
    "# date = list()\n",
    "# for i in df['Year']:\n",
    "#     date.append(datetime.strptime(str(i),'%Y.%M'))\n",
    "\n",
    "# df['Year'] = date\n",
    "# df\n",
    "\n",
    "# value = '2011/01/03'\n",
    "f = lambda x :datetime.strptime(str(int(x)), '%Y')\n",
    "\n",
    "df['Year'] = df['Year'].apply(f)\n",
    "df\n",
    "# output\n",
    "#  d.)  Split a dataset to group by two columns and then sort the aggregated results within the groups\n",
    "#It creates groups based on unique combinations of these two columns\n",
    "\n",
    "# Group by  and  and calculate the mean within each group\n",
    "\n",
    "#.reset_index(): The reset_index() function is used to reset the index of \n",
    "\n",
    "#the resulting DataFrame. When you perform a groupby and aggregation, the grouped columns\n",
    "\n",
    "#('Genre' and 'Year' in this case) become part of the index. reset_index() moves these columns\n",
    "\n",
    "#back to regular columns and gives the DataFrame a default integer index.\n",
    "grouped = df.groupby(['Genre', 'Year']).agg({'Global': 'mean'}).reset_index()\n",
    "grouped\n",
    "# output\n",
    "# Sort the aggregated results within each group\n",
    "grouped.sort_values(by=['Global'])\n",
    "# output\n",
    "#  e.) Split a given dataframe into groups with bin counts.\n",
    "\n",
    "# df.groupby(['Genre', pd.cut(df['Global'], 5)]): This part of the code groups the DataFrame \n",
    "\n",
    "# df by two columns: 'Genre' and a new column created using pd.cut(df['Global'], 5).\n",
    "\n",
    "# The pd.cut function is used to bin the 'Global' column into 5 equal-width bins. \n",
    "\n",
    "# This results in grouping data based on both the 'Genre' and the bin (range of values)\n",
    "\n",
    "# to which each 'Global' value belongs.\n",
    "\n",
    "# grouped.size(): After grouping, the size() function is applied to count the number of \n",
    "\n",
    "grouped = df.groupby(['Genre', pd.cut(df['Global'],5)])\n",
    "\n",
    "#After grouping, the size() function is applied to count the number of occurrences in each group.\n",
    "\n",
    "grouped.size().unstack()\n",
    "# output\n",
    "\n",
    "# question 7\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('student_data.csv')\n",
    "\n",
    "df\n",
    "# output\n",
    "pd.get_dummies(df['Gender'])\n",
    "#categorival variale\n",
    "#one hot encoding - we create a new  column for each of our category and\n",
    "# assign binary value 1 or 0\n",
    "# output\n",
    "#  a.)  Perform one hot encoding of the last two columns of categorical data using the get_dummies() function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "gender_encoded = pd.get_dummies(df['Gender'])       # hot encoding og gender\n",
    "pass_d_encoded = pd.get_dummies(df['Pass_Division'])   # hot encoding og pass division\n",
    "\n",
    "pd.concat([df,hot_encodes,pass_d_encoded],axis='columns')\n",
    "# output\n",
    "#  b. Sort this data frame on the “Birth Month” column (i.e. January to December). Hint: Convert Month to Categorical.\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Convert 'Birth Month' to categorical with specified order\n",
    "\n",
    "#This line uses the pd.Categorical function to convert the 'Birth_Month' column of the DataFrame (df) \n",
    "# to a categorical type. The categories parameter is set to month_order, specifying the desired order \n",
    "# of the categories\n",
    "\n",
    "df['Birth_Month'] = pd.Categorical(df['Birth_Month'], categories=month_order, ordered=True)\n",
    "\n",
    "df.sort_values(by='Birth_Month')\n",
    "# output\n",
    "from jupyterthemes import get_themes\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "\n",
    "# List available themes\n",
    "themes = get_themes()\n",
    "print(themes)\n",
    "\n",
    "# Set a theme (choose one from the list)\n",
    "set_nb_theme('monokai')\n",
    "# output\n",
    "\n",
    "# question 8\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('income_data.csv')\n",
    "df\n",
    "# output\n",
    "# a.)  Calculate and display familywise gross monthly income. \n",
    "\n",
    "df.groupby(['Name'])['MonthlyIncome (Rs.)'].sum()\n",
    "# output\n",
    "#  b.) Calculate and display the member with the highest monthly income in a family\n",
    "\n",
    "df.groupby(['Name'])['MonthlyIncome (Rs.)'].max()\n",
    "# output\n",
    "#  c.)  Calculate and display monthly income of all members with income greater than Rs. 60000.00\n",
    "\n",
    "df[df['MonthlyIncome (Rs.)'] > 60000]\n",
    "# output\n",
    "# d.) Calculate and display the average monthly income of the female members in the Shah family.\n",
    "\n",
    "df[df['Name'] == 'Shah']['MonthlyIncome (Rs.)'].mean()\n",
    "# output\n",
    "from jupyterthemes import get_themes\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "\n",
    "# List available themes\n",
    "themes = get_themes()\n",
    "print(themes)\n",
    "\n",
    "# Set a theme (choose one from the list)\n",
    "set_nb_theme('monokai')\n",
    "# output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca24ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ed8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
