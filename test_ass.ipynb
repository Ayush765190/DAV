{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1508b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1\n",
    "List1 = ['data ', ' Data mining', 'Machine Learning ', ' Analysis and Visualization', 'I work with Data']\n",
    "List1\n",
    "\n",
    "clean_ops=[str.strip,str.title]\n",
    "def clean_strings(strings,ops):\n",
    "    result=[]\n",
    "    for value in strings:\n",
    "        for function in ops:\n",
    "            value=function(value)\n",
    "        result.append(value)\n",
    "    return result\n",
    "\n",
    "new=clean_strings(List1,clean_ops)\n",
    "print(new)\n",
    "\n",
    "import itertools\n",
    "first_letter = lambda x : x[0]\n",
    "for letter, name in itertools.groupby(new,first_letter):\n",
    "    print(letter,list(name))\n",
    "\n",
    "def squares_generator(n):\n",
    "    for i in range(1, n + 1):\n",
    "        yield i ** 2\n",
    "\n",
    "# Taking user input for 'n'\n",
    "n = int(input(\"Enter the value of n: \"))\n",
    "\n",
    "# Using the generator to print squares of first 'n' natural numbers\n",
    "squares = squares_generator(n)\n",
    "print(f\"Squares of the first {n} natural numbers:\")\n",
    "for square in squares:\n",
    "    print(square)\n",
    "\n",
    "\n",
    "arr=[3,5,7,4,6,8,12,9]\n",
    "total_until_4=0\n",
    "for value in arr:\n",
    "    if value ==4:\n",
    "        break\n",
    "    total_until_4+=value \n",
    "print(\"total is : \",total_until_4+4)\n",
    "\n",
    "arr[2:5]\n",
    "\n",
    "arr\n",
    "\n",
    "arr[-5:-1]\n",
    "\n",
    "arr[ : : 2]\n",
    "\n",
    "arr[3:4]=[16,12]\n",
    "arr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "arr1=np.array(arr)\n",
    "\n",
    "arr1\n",
    "\n",
    "arr1=arr1.reshape(3,3)\n",
    "\n",
    "arr1\n",
    "\n",
    "np.sum(arr1,axis=1)\n",
    "\n",
    "np.dot(arr1.T,arr1)\n",
    "\n",
    "np.ones_like(arr1)\n",
    "\n",
    "\n",
    "# test20\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {\n",
    "'Date': ['2021-01-05', '2021-01-12', '2021-01-19', '2021-01-19', '2021-02-02'], \n",
    "    'Product': ['A', 'B', 'A', 'C', 'B'],\n",
    "    'Sales': [150, 200, 120, 180, 250]\n",
    "}\n",
    "sales_data = pd.DataFrame(data)\n",
    "\n",
    "sales_data['Date'] = pd.to_datetime(sales_data['Date'], format='%Y-%m-%d')\n",
    "\n",
    "sales_data\n",
    "\n",
    "sales_data.set_index('Date', inplace=True)\n",
    "\n",
    "sales_data\n",
    "\n",
    "sales_data.set_index('Date', inplace = True)\n",
    "\n",
    "if sales_data.index.is_unique: \n",
    "    print(\"The index is unique.\")\n",
    "else:\n",
    "    grouped_data = sales_data.groupby(level='Date').mean() \n",
    "    print(\"The index is not unique. Grouped Data:\") print(grouped_data)\n",
    "\n",
    "truncated_data = sales_data.truncate(after='2021-01-20')\n",
    "print(truncated_data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Marks data\n",
    "math_marks = [12, 4, 14, 15, 13]\n",
    "science_marks = [11, 10, 13, 9, 13]\n",
    "# Scatter plot\n",
    "plt.scatter(range(1, 6), math_marks, color='red', label='Mathematics Marks')\n",
    "plt.scatter(range(1, 6), science_marks, color='blue', label='Science Marks')\n",
    "# Title and Labels\n",
    "plt.title('Marks Comparison')\n",
    "plt.xlabel('Student')\n",
    "plt.ylabel('Marks Scored')\n",
    "# Legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Load sales_data.csv into a DataFrame\n",
    "sales_data = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Load region_data.csv into a DataFrame\n",
    "region_data = pd.read_csv('region_data.csv')\n",
    "\n",
    "sales_data\n",
    "\n",
    "region_data\n",
    "\n",
    "# Task 2: Implement hierarchical indexing on sales_data with Levels Region and Product \n",
    "sales_data.set_index(['Region', 'Product'], inplace=True)\n",
    "\n",
    "sales_data\n",
    "\n",
    "#Sort the sales_data DataFrame based on the Region level in ascending order \n",
    "sales_data.sort_index(level='Region', inplace=True)\n",
    "\n",
    "# Task 5: Identify the date with the highest total sales \n",
    "date_highest_total_sales = sales_data.groupby('Date') ['Sales'].sum().idxmax() \n",
    "date_highest_total_sales\n",
    "\n",
    "#Merge sales_data and region_data based on the Region column\n",
    "merged_data = pd.merge(sales_data.reset_index(), region_data, on='Region', how='left')\n",
    "\n",
    "merged_data\n",
    "\n",
    "# Task 2: Use groupby to Calculate total sales for each region and assign it to \n",
    "total_ total_sales_by_region = sales_data.groupby('Region') ['Sales'].sum() \n",
    "total_sales_by_region\n",
    "\n",
    "# Task 6: Group sales_data by both 'Region' and 'Product', and calculate sum of sales \n",
    "grouped_data = sales_data.groupby(['Region', 'Product']).agg({'Sales': 'sum', 'Quantity':'avg'}) \n",
    "grouped_data\n",
    "\n",
    "# Task 5: Concatenate sales_data and region_data along the rows and name the resultant \n",
    "concatenated_data = pd.concat([sales_data.reset_index(), region_data], axis=0)\n",
    "concatenated_data\n",
    "\n",
    "# The resulting data will have missing values too, Fill missing values in the concaten \n",
    "concatenated_data['Sales'].fillna (concatenated_data['Sales'].mean(), inplace=True)\n",
    "concatenated_data\n",
    "\n",
    "# Task 7: Save the results obtained in last example to 'sales_analysis.csv' \n",
    "concatenated_data.to_csv('sales_analysis.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# assignment\n",
    "# q1\n",
    "import pandas as pd\n",
    "\n",
    "book_dataset = pd.read_csv('bestsellers.csv')\n",
    "\n",
    "book_dataset\n",
    "\n",
    "book_dataset.head()\n",
    "\n",
    "book_dataset.describe()\n",
    "\n",
    "book_dataset[book_dataset['Author']=='Pete Souza']\n",
    "\n",
    "book_dataset[book_dataset['Price'].between(50,60)]\n",
    "\n",
    "arr = ['Kristin Hannah','Andy Weir','Delia Owens']\n",
    "for i in arr:\n",
    "    print(book_dataset[book_dataset['Author']== i])\n",
    "\n",
    "book_dataset[book_dataset['Author'].isin(arr)]\n",
    "\n",
    "temp=book_dataset[book_dataset['Year']==2012]\n",
    "temp\n",
    "\n",
    "temp.sort_values(by='Reviews',ascending=False).head()\n",
    "\n",
    "import numpy as np\n",
    "pd.pivot_table(book_dataset,values='Price',index='Genre', columns ='Author',aggfunc=np.sum)\n",
    "\n",
    "pd.pivot_table(book_dataset,values=['Price','User Rating'],index='Year',aggfunc=np.mean)\n",
    "\n",
    "book_dataset['Bins'] =pd.cut(book_dataset['Price'],5)\n",
    "book_dataset.groupby('Bins')['Reviews'].agg(np.sum)\n",
    "\n",
    "pd.pivot_table(book_dataset,values='Price',index=['Genre','Year'],aggfunc=np.mean)\n",
    "\n",
    "t=book_dataset[book_dataset['User Rating']<4.5]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "tp = t.groupby('Author').count()\n",
    "\n",
    "data = tp.sort_values(by='Name',ascending=False).head()\n",
    "data\n",
    "\n",
    "plt.bar(data.index,data.Name)\n",
    "\n",
    "\n",
    "# q2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "stats = pd.read_csv('sports.csv')\n",
    "stats.columns\n",
    "\n",
    "stats['Red Cards']\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "red_cards = stats.groupby('Team')['Red Cards'].agg(np.sum)\n",
    "red_cards\n",
    "\n",
    "red_cards.sort_values(ascending=False).head()\n",
    "\n",
    "stats.groupby('Position')['Long passes'].agg(np.mean)\n",
    "\n",
    "tt01 = stats[stats['Shirt number'] ==10.0]\n",
    "\n",
    "tt01\n",
    "\n",
    "tt01.sort_values(by='Goals scored',ascending=False).head(12)\n",
    "\n",
    "# q3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "stats = pd.read_csv('sports.csv')\n",
    "total = stats.groupby('Team')['Shots'].agg(np.sum)\n",
    "\n",
    "on_target = stats.groupby('Team')['Shots on target'].agg(np.sum)\n",
    "on_target\n",
    "\n",
    "df = pd.merge(total, on_target,on='Team')\n",
    "df\n",
    "\n",
    "df = df.rename(columns={'Shots':'total','Shots on target':'on_target'})\n",
    "\n",
    "df['per'] =  (df['on_target'] /df['total'])\n",
    "df= df.sort_values(by='per')\n",
    "\n",
    "tt=df.head()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(tt.index,tt['per'],color='red')\n",
    "\n",
    "plt.xlabel('On Target Percentage')\n",
    "plt.title('Least Accurate Teams')\n",
    "plt.show()\n",
    "\n",
    "tt1 = df.tail()\n",
    "\n",
    "plt.barh(tt1.index,tt1['per'],color='green')\n",
    "\n",
    "plt.xlabel('On Target Percentage')\n",
    "plt.title('Most Accurate Teams')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# test24\n",
    "\n",
    "# QUE 1 Write code to \n",
    "# (i) Create a datetime index for all second Tuesdays of every month in 2021 (ii) Create the first \n",
    "# data series with random floating-point numbers (iii) Apply a forward shift of 3 periods to series1 \n",
    "# and name the new series series1_shifted (iv) Create the second data series with a datetime index \n",
    "# of 20 continuous dates ending at 31/01/2021 (v) Modify code for series 2 to create a date index \n",
    "# containing the last business day of each month \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "# (1) Create a datetime index for all second Tuesdays of every month in 2021 \n",
    "start_date = \"2021-01-01\" \n",
    "end_date = \"2021-12-31\" \n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='WOM-2TUE\") \n",
    "# (11) Create the first data series with random floating-point numbers \n",
    "series1 = pd.Series(np.random.randn(len(date_range)), index=date_range) \n",
    "# (1i1) Apply a forward shift of 3 periods to seriesl and name the new series seriesl_ \n",
    "seriesl_shifted = series1.shift(3) \n",
    "# (iv) Create the second data series with a datetime index of 20 continuous dates endi \n",
    "end_date_series2 = \"2021-01-31\" \n",
    "date_range_series2 = pd.date_range(end=end_date_series2, periods=20) \n",
    "# (v) Modify code for series 2 to create a date index containing the last business day \n",
    "last_business_day_index_series2 = pd.date_range(start=date_range_series2[0], end=date_ \n",
    "# Create the second data series with random floating-point numbers \n",
    "series2 = pd.Series(np.random.randn(len(date_range_series2)), index=date_range_series: \n",
    "# Print the results \n",
    "print(\"Datetime Index for Second Tuesdays of Every Month in 2021: \n",
    "print(date_range) \n",
    "print(\"\\nSeries 1:\") \n",
    "print(series1) \n",
    "print(\"\\nSeries 1 Shifted:\") \n",
    "print(series1_shifted) \n",
    "print(\"\\nDatetime Index for 20 Continuous Dates Ending at 31/01/2021:\") \n",
    "print(date_range_series2) \n",
    "print(\"\\nLast Business Day Index for Series 2:\") \n",
    "print(last_business_day_index_series2) \n",
    "print(\"\\nSeries 2:\") \n",
    "print(series2) \n",
    "      \n",
    "# QUE 2 \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Data for the DataFrame \n",
    "EXERCISE = { \n",
    "‘Name': ['Personl', 'Person2', 'Person3', 'Person4', 'Person5', 'Person2'], \n",
    "‘Gender': ['Male', 'Female’, np.nan, 'Male', 'Male', 'Female'], \n",
    "‘Diet': ['Low_Carb', 'High_Carb', 'High_Carb', 'High_Carb', 'High_Carb', 'High_Car \n",
    "‘Exercise_Time': [92, 81, 33, 52, 44, 81], \n",
    "‘Calories_Burned': [227, 138, 437, 459, 228, 138] \n",
    "}\n",
    "# Create the DataFrame \n",
    "EXERCISE = pd.DataFrame(EXERCISE) \n",
    "# Display the DataFrame \n",
    "print(EXERCISE) \n",
    "    \n",
    "# Assuming the data is stored in a csv file “Exercise.csv”, give appropriate commands to (i) read \n",
    "# this file, indexed on ‘Name' and ‘Diet’ into a dataframe named EXERCISE. (ii) replace missing \n",
    "# values with zeros, and remove duplicate values in the dataframe (iii) read only the first 3 rows of \n",
    "# the file. (iv) Create a new column 'ID' by concatenating the first two characters of ‘Name' with \n",
    "# the last two characters of 'Diet’ (v) Read the file in small pieces of uniform size (e.g., chunk size \n",
    "# of 1000 records) (vi) compute inter-column correlations for the last 2 columns (vii) Group the \n",
    "# DataFrame ‘EXERCISE’ based on the level ‘Gender' of the hierarchical index and compute the \n",
    "# sum of the 'Calories_Burned' for each gender group. (viii) Create a hierarchical index with levels \n",
    "# ‘Gender' and 'Diet’ and name it ‘Hier_Exercise’ (ix) Suppose you have one more dataframe \n",
    "# named ‘Exercise 1\", write code to Merge EXERCISE and EXERCISE2 based on the 'Name' column. \n",
    "# (x) Write the modified data back to the original file. \n",
    "    \n",
    "    \n",
    "# Read the file, indexed on 'Name' and 'Diet’ \n",
    "#import pandas as pd \n",
    "#EXERCISE = pd.read_csv(\"Exercise.csv”, index_col=['Name', 'Diet']) \n",
    "# Replace missing values with zeros \n",
    "EXERCISE.fillna(0, inplace=True) \n",
    "# Remove duplicate values \n",
    "EXERCISE.drop_duplicates(inplace=True) \n",
    "EXERCISE \n",
    "# Read only the first 3 rows \n",
    "first_3_rows = pd.read_csv(\"Exercise.csv\", index_col=[\"'Name', 'Diet'], nrows=3) \n",
    "# Create a new column 'ID' \n",
    "EXERCISE[ 'ID'] = EXERCISE['Name'].str[:2] + EXERCISE['Diet'].str[-2:] \n",
    "# Read the file 1in small pieces of uniform size \n",
    "chunk_size = 1000 \n",
    "chunks = pd.read_csv(\"Exercise.csv\", index_col=['Name', 'Diet'], chunksize=chunk_size) \n",
    "# Example: Iterate over chunks \n",
    "for chunk in chunks: \n",
    "# Process each chunk as needed \n",
    "print(chunk) \n",
    "# Compute inter-column correlations for the last 2 columns \n",
    "correlations = EXERCISE.iloc[:, -2:].corr() \n",
    "# Group by 'Gender' and compute the sum of 'Calories_Burned\" \n",
    "gender_sum_calories = EXERCISE.groupby(level=\"Gender')['Calories_Burned'].sum() \n",
    "\n",
    "# Create a hierarchical index with levels 'Gender' and 'Diet’ \n",
    "EXERCISE.set_index(['Gender', 'Diet'], inplace=True) \n",
    "# Name the resulting index 'Hier_Exercise' \n",
    "EXERCISE.index = EXERCISE.index.set_names(['Gender', 'Diet'], names=['Hier_Exercise']) \n",
    " \n",
    "# Assuming you have another DataFrame named EXERCISE2 \n",
    "# If not, replace EXERCISE2 with the actual DataFrame name \n",
    "# Merge based on the 'Name' column \n",
    "merged_exercise = pd.merge(EXERCISE, EXERCISE2, on='Name') \n",
    "# Write the modified data back to the original file \n",
    "EXERCISE.to_csv(\"Exercise.csv\") \n",
    "                                       \n",
    "# For the following Data categories = ['Category A', 'Category B', 'Category C', 'Category D'] values \n",
    "# = [25, 40, 30, 50] (i) Create a bar chart with ‘categories' on the x-axis and 'values' on the y-axis. \n",
    "# (i) Add appropriate labels to the axes and a title to the chart. (iii) Display the chart. (iv) what \n",
    "# modification can be done to convert it into a stacked horizontal bar chart \n",
    "                                       \n",
    "import matplotlib.pyplot as plt \n",
    "# Data \n",
    "categories = ['Category A', 'Category B', 'Category C', 'Category D'] \n",
    "values = [25, 40, 30, 50] \n",
    "# Create a bar chart \n",
    "plt.bar(categories, values) \n",
    "# Add Labels and title \n",
    "plt.xlabel('Categories') \n",
    "plt.ylabel('Values') \n",
    "plt.title('Bar Chart Example') \n",
    "# Display the chart \n",
    "plt.show() \n",
    "# Create a stacked horizontal bar chart \n",
    "plt.barh(categories, values, color=['red', 'green', 'blue', 'orange']) \n",
    "# Add Labels and title \n",
    "plt.xlabel('Values') \n",
    "plt.ylabel('Categories') \n",
    "plt.title('Stacked Horizontal Bar Chart Example') \n",
    "# Display the chart \n",
    "plt.show()    \n",
    "                                       \n",
    "                                       \n",
    "                                       \n",
    "# extra test\n",
    "\n",
    "Que 1-\n",
    "import pandas as pd\n",
    "# Given DataFrame\n",
    "data = {\n",
    "'Product': ['Product_A', 'Product_B', 'Product_A', 'Product_C', 'Product_B', 'Product_A'],\n",
    "'Price': [30, 90, 120, 60, 80, 150]\n",
    "}\n",
    "i) Drop Duplicates\n",
    "ii) Convert product column values to Lowercase\n",
    "iii) Rename Values\n",
    "iv) Create Bins for price as low, medium, high and very high\n",
    "Que 2-\n",
    "import pandas as pd\n",
    "sales_data = pd.DataFrame({\n",
    "'Product': ['A', 'B', 'A', 'C', 'B', 'A'],\n",
    "'Quantity': [30, 20, 25, 15, 10, 35],\n",
    "'CustomerID': [101, 102, 103, 101, 104, 102]\n",
    "})\n",
    "customer_data = pd.DataFrame({\n",
    "'CustomerID': [101, 102, 103, 104],\n",
    "'CustomerName': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "i) Group the sales_data DataFrame by the \"Product\" column and calculate the total quantity\n",
    "sold for each product.\n",
    "ii) Merge the sales_data and customer_data DataFrames using the \"CustomerID\" column.\n",
    "iii) Create a new DataFrame named merged_data with a hierarchical index. Use \"Product\" as\n",
    "the first level and \"CustomerID\" as the second level.\n",
    "iv) Plot a bar chart to visualize the total quantity sold for each product after the merge.\n",
    "Que 3-\n",
    "Consider a scenario where you have a DataFrame named temperature_data containing temperature\n",
    "records with a \"Date\" column. Perform the following tasks using pandas:\n",
    "i) Date Range Generation: Create a date range for the entire year of 2023 with a frequency\n",
    "of one day. Create temperature values randomly . Name the resulting Series as\n",
    "date_series.\n",
    "ii) Convert the \"Temperature\" column in temperature_data to categorical data with three\n",
    "categories: \"Low\" for temperatures below 20°C, \"Medium\" for temperatures between\n",
    "20°C and 30°C, and \"High\" for temperatures above 30°C. Name the resulting categorical\n",
    "column as Temperature_Category.\n",
    "iii) Resampling: Resample the temperature_data DataFrame to a monthly frequency,\n",
    "calculating the mean temperature for each month. Name the resulting DataFrame as\n",
    "monthly_temperatures.  \n",
    "                                                      \n",
    "                                                      \n",
    "import pandas as pd\n",
    "# Given DataFrame\n",
    "data = {\n",
    "'Product': ['Product_A', 'Product_B', 'Product_A', 'Product_C', 'Product_B', 'Product_A'],\n",
    "'Price': [30, 90, 120, 60, 80, 150]\n",
    "}\n",
    "sales_data = pd.DataFrame(data)\n",
    "# 1. Drop Duplicates\n",
    "sales_data.drop_duplicates(subset='Product', inplace=True)\n",
    "# 2. Convert to Lowercase\n",
    "sales_data['Product'] = sales_data['Product'].str.lower()\n",
    "# 3. Rename Values\n",
    "sales_data['Product'] = sales_data['Product'].replace({'product_a': 'New_Product_A', 'product_b':\n",
    "'New_Product_B'})\n",
    "# 4. Create Bins\n",
    "bins = [0, 50, 100, 150, 200]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "sales_data['Price_Category'] = pd.cut(sales_data['Price'], bins=bins, labels=labels)\n",
    "# Display the cleaned DataFrame\n",
    "print(sales_data)\n",
    "                                                      \n",
    "Solution 2-\n",
    "                                                      \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Given DataFrames\n",
    "sales_data = pd.DataFrame({\n",
    "'Product': ['A', 'B', 'A', 'C', 'B', 'A'],\n",
    "'Quantity': [30, 20, 25, 15, 10, 35],\n",
    "'CustomerID': [101, 102, 103, 101, 104, 102]\n",
    "})\n",
    "customer_data = pd.DataFrame({\n",
    "'CustomerID': [101, 102, 103, 104],\n",
    "'CustomerName': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "# 1. Group By\n",
    "product_quantity = sales_data.groupby('Product')['Quantity'].sum()\n",
    "# 2. Data Merging\n",
    "merged_data = pd.merge(sales_data, customer_data, on='CustomerID')  \n",
    "                                                      \n",
    "                                                      \n",
    "# 3. Hierarchical Indexing\n",
    "merged_data.set_index(['Product', 'CustomerID'], inplace=True)\n",
    "# 4. Plotting\n",
    "product_quantity.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Total Quantity Sold')\n",
    "plt.title('Total Quantity Sold by Product')\n",
    "plt.show()\n",
    "                                                      \n",
    "Solution 3-\n",
    "                                                      \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Given DataFrame\n",
    "np.random.seed(42)\n",
    "date_rng = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "temperature_data = pd.DataFrame({\n",
    "'Date': date_rng,\n",
    "'Temperature': np.random.randint(10, 35, size=(len(date_rng)))\n",
    "})\n",
    "# 1. Date Range Generation\n",
    "date_series = pd.Series(pd.date_range(start='2023-01-01', end='2023-12-31', freq='D'), name='Date')\n",
    "# 2. Categorical Data\n",
    "temperature_data['Temperature_Category'] = pd.cut(temperature_data['Temperature'],\n",
    "bins=[-np.inf, 20, 30, np.inf],\n",
    "\n",
    "labels=['Low', 'Medium', 'High']).astype('category')\n",
    "\n",
    "# 3. Resampling\n",
    "temperature_data.set_index('Date', inplace=True)\n",
    "monthly_temperatures = temperature_data.resample('M').mean()\n",
    "# Display the results\n",
    "print(\"Date Series:\")\n",
    "print(date_series.head())\n",
    "print(\"\\nTemperature Data with Categorical Column:\")\n",
    "print(temperature_data.head())\n",
    "print(\"\\nMonthly Temperatures:\")\n",
    "print(monthly_temperatures.head())                                                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
